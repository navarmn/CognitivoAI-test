{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Source code\n",
    "from transforms import *\n",
    "import experiment\n",
    "\n",
    "# Global variables\n",
    "MODELS_FOLDER = os.path.join('..', 'models')\n",
    "PIPELINE_NAME = 'pipeline.pkl'\n",
    "DATA_FOLDER = os.path.join('..', 'data')\n",
    "DATA_FOLDER_RAW = os.path.join(DATA_FOLDER, 'raw')\n",
    "DATA_NAME_RAW = 'winequality_90.csv'\n",
    "SEED = 93849823\n",
    "ACTION = 'load' # set \"load\" to just load the results or \"train\" to train them all again\n",
    "\n",
    "# Warnings off:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Set the random state seed for reproducibility\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.073</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99638</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.047</td>\n",
       "      <td>21.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.034</td>\n",
       "      <td>49.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.98882</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.43</td>\n",
       "      <td>13.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.037</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.99040</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>11.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.038</td>\n",
       "      <td>44.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99260</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0    Red            8.2             0.635         0.10             2.1   \n",
       "1  White            5.7             0.100         0.27             1.3   \n",
       "2  White            6.9             0.280         0.24             2.1   \n",
       "3  White            5.8             0.360         0.38             0.9   \n",
       "4  White            7.4             0.200         0.36             1.2   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.073                 25.0                  60.0  0.99638  3.29   \n",
       "1      0.047                 21.0                 100.0  0.99280  3.27   \n",
       "2      0.034                 49.0                 121.0  0.98882  2.98   \n",
       "3      0.037                  3.0                  75.0  0.99040  3.28   \n",
       "4      0.038                 44.0                 111.0  0.99260  3.36   \n",
       "\n",
       "   sulphates alcohol  quality  \n",
       "0       0.75    10.9        6  \n",
       "1       0.46     9.5        5  \n",
       "2       0.43    13.2        7  \n",
       "3       0.34    11.4        4  \n",
       "4       0.34     9.9        6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(DATA_FOLDER_RAW, DATA_NAME_RAW))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build the pipeplinr from scratch by using the classes under the `transforms.py`. However, we already did that and we encourage you to use the `pipeline.pkl`, which has been built using `sklearn` structured and pipeline class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cleaner', DataCleaning()),\n",
       " ('remover', RemoveFeatures(features='type')),\n",
       " ('scaler', FeatureScaling(type='std')),\n",
       " ('droper', <transforms.DropNaN at 0x7fe6fae6d278>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = joblib.load(os.path.join(MODELS_FOLDER, PIPELINE_NAME))\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how to use the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, ..., 4, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = GetLables().fit_transform(data)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.073</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99638</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.047</td>\n",
       "      <td>21.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.034</td>\n",
       "      <td>49.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.98882</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.43</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.037</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.99040</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.038</td>\n",
       "      <td>44.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99260</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0    Red            8.2             0.635         0.10             2.1   \n",
       "1  White            5.7             0.100         0.27             1.3   \n",
       "2  White            6.9             0.280         0.24             2.1   \n",
       "3  White            5.8             0.360         0.38             0.9   \n",
       "4  White            7.4             0.200         0.36             1.2   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.073                 25.0                  60.0  0.99638  3.29   \n",
       "1      0.047                 21.0                 100.0  0.99280  3.27   \n",
       "2      0.034                 49.0                 121.0  0.98882  2.98   \n",
       "3      0.037                  3.0                  75.0  0.99040  3.28   \n",
       "4      0.038                 44.0                 111.0  0.99260  3.36   \n",
       "\n",
       "   sulphates alcohol  \n",
       "0       0.75    10.9  \n",
       "1       0.46     9.5  \n",
       "2       0.43    13.2  \n",
       "3       0.34    11.4  \n",
       "4       0.34     9.9  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.drop('quality', axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.753317</td>\n",
       "      <td>1.794928</td>\n",
       "      <td>-1.511482</td>\n",
       "      <td>-0.701777</td>\n",
       "      <td>0.474572</td>\n",
       "      <td>-0.311825</td>\n",
       "      <td>-0.986257</td>\n",
       "      <td>-0.092347</td>\n",
       "      <td>0.440301</td>\n",
       "      <td>1.454997</td>\n",
       "      <td>0.347380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.168491</td>\n",
       "      <td>-1.453357</td>\n",
       "      <td>-0.336296</td>\n",
       "      <td>-0.869575</td>\n",
       "      <td>-0.258709</td>\n",
       "      <td>-0.536331</td>\n",
       "      <td>-0.279840</td>\n",
       "      <td>-0.092822</td>\n",
       "      <td>0.315747</td>\n",
       "      <td>-0.474754</td>\n",
       "      <td>-0.831347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.246023</td>\n",
       "      <td>-0.360476</td>\n",
       "      <td>-0.543682</td>\n",
       "      <td>-0.701777</td>\n",
       "      <td>-0.625349</td>\n",
       "      <td>1.035214</td>\n",
       "      <td>0.091029</td>\n",
       "      <td>-0.093351</td>\n",
       "      <td>-1.490295</td>\n",
       "      <td>-0.674383</td>\n",
       "      <td>2.283859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.091618</td>\n",
       "      <td>0.125249</td>\n",
       "      <td>0.424119</td>\n",
       "      <td>-0.953474</td>\n",
       "      <td>-0.540740</td>\n",
       "      <td>-1.546611</td>\n",
       "      <td>-0.721351</td>\n",
       "      <td>-0.093141</td>\n",
       "      <td>0.378024</td>\n",
       "      <td>-1.273271</td>\n",
       "      <td>0.768353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.138338</td>\n",
       "      <td>-0.846201</td>\n",
       "      <td>0.285862</td>\n",
       "      <td>-0.890550</td>\n",
       "      <td>-0.512537</td>\n",
       "      <td>0.754581</td>\n",
       "      <td>-0.085575</td>\n",
       "      <td>-0.092849</td>\n",
       "      <td>0.876242</td>\n",
       "      <td>-1.273271</td>\n",
       "      <td>-0.494568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       0.753317          1.794928    -1.511482       -0.701777   0.474572   \n",
       "1      -1.168491         -1.453357    -0.336296       -0.869575  -0.258709   \n",
       "2      -0.246023         -0.360476    -0.543682       -0.701777  -0.625349   \n",
       "3      -1.091618          0.125249     0.424119       -0.953474  -0.540740   \n",
       "4       0.138338         -0.846201     0.285862       -0.890550  -0.512537   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0            -0.311825             -0.986257 -0.092347  0.440301   1.454997   \n",
       "1            -0.536331             -0.279840 -0.092822  0.315747  -0.474754   \n",
       "2             1.035214              0.091029 -0.093351 -1.490295  -0.674383   \n",
       "3            -1.546611             -0.721351 -0.093141  0.378024  -1.273271   \n",
       "4             0.754581             -0.085575 -0.092849  0.876242  -1.273271   \n",
       "\n",
       "    alcohol  \n",
       "0  0.347380  \n",
       "1 -0.831347  \n",
       "2  2.283859  \n",
       "3  0.768353  \n",
       "4 -0.494568  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_transformed = pipeline.fit_transform(features)\n",
    "features_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 5844, 5845, 5846])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_transformed.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5813,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels[features_transformed.index.values]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 01:\n",
    "- All classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_experiment(results_name, folder, features, labels, n_classes=2, action='load', classifiers={}, kfold=10):\n",
    "    print(action)\n",
    "    if action=='train':\n",
    "        print(folder)\n",
    "        # Train all clf\n",
    "        ### Stratified cross-validation for model selection will be used.\n",
    "\n",
    "        clf_outputs = experiment.run_classifiers(features, labels, classifiers, kfolds)\n",
    "\n",
    "        ## Performance assessment\n",
    "        results = {}\n",
    "        results['train'] = experiment.results_clf(n_classes, clf_outputs['train']['true'], clf_outputs['train']['pred'])\n",
    "        results['test'] = experiment.results_clf(n_classes, clf_outputs['test']['true'], clf_outputs['test']['pred'])\n",
    "\n",
    "        ## Save results\n",
    "        experiment.export_results(results['test'], 'test', foldertree=folder)\n",
    "        experiment.export_results(results['train'], 'train', foldertree=folder)\n",
    "\n",
    "        name = os.path.join(folder, results_name)\n",
    "        joblib.dump(results, name)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    elif action == 'load':\n",
    "        name = os.path.join(folder, results_name)\n",
    "        return joblib.load('{}'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "results_obj_name = 'results-01-clf-all.pkl'\n",
    "results_folder = os.path.join('Results-analyses-3', '01-all-clf')\n",
    "kfolds = 10\n",
    "n_classes = 2\n",
    "\n",
    "# Define all classifiers:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# No hyperparameter tunning for now. They default setting will be used.\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "random_forest_clf = RandomForestClassifier()\n",
    "naive_bayes_clf = GaussianNB()\n",
    "gaussian_linear_clf = LinearDiscriminantAnalysis()\n",
    "gaussian_quadratic_clf = QuadraticDiscriminantAnalysis()\n",
    "perceptron_clf = Perceptron()\n",
    "sgd_clf = SGDClassifier()\n",
    "\n",
    "# MLP:\n",
    "mlp_clf = MLPClassifier(solver='adam', learning_rate='adaptive', \n",
    "                        max_iter=1300, learning_rate_init=5e-04, tol=1e-4)\n",
    "\n",
    "mlp_clf_2 = MLPClassifier(solver='lbfgs', learning_rate='adaptive', \n",
    "                        max_iter=1300, learning_rate_init=5e-04, tol=1e-4)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('mlp', mlp_clf), ('mlp-2', mlp_clf_2), ('naive-bayes', naive_bayes_clf)], \n",
    "                        voting='soft', weights=[0.75, 0.75, 1.4])\n",
    "\n",
    "# Place them all in a dict\n",
    "\n",
    "classifiers = {'KNN': knn_clf, 'RF': random_forest_clf, 'Naive_bayes': naive_bayes_clf,\n",
    "               'Gaussian_linear': gaussian_linear_clf, 'Gaussian_quadratic': gaussian_quadratic_clf,\n",
    "               'Perceptron': perceptron_clf, 'SGDClassifier': sgd_clf,\n",
    "               'MLP': mlp_clf,\n",
    "               'Ensemble': eclf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Results-analyses-3/01-all-clf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "results_exp_01 = do_experiment(results_obj_name, results_folder, features=features_transformed.values, labels=labels.ravel(), \n",
    "                               classifiers=classifiers, n_classes=np.unique(labels).shape[0], action='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The results from this part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_results(results):\n",
    "    result_df = pd.DataFrame(columns=['acc', 'recall', 'precision'], index=results['test'].keys())\n",
    "    \n",
    "    for clf in results['test'].keys():\n",
    "        result_df.loc[clf]['acc'] = results['test'][clf]['average']['acc']\n",
    "        result_df.loc[clf]['recall'] = results['test'][clf]['average']['recall']\n",
    "        result_df.loc[clf]['precision'] = results['test'][clf]['average']['precision']\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_clf_all = see_results(results_exp_01)\n",
    "result_df_clf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(15,6))\n",
    "sns.barplot(y='acc', x=result_df_clf_all.index, data=result_df_clf_all)\n",
    "plt.ylim(0.967, 0.99)\n",
    "plt.title('Average ACC (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1,figsize=(15,10))\n",
    "sns.barplot(y='recall', x=result_df_clf_all.index, data=result_df_clf_all, ax = axes[0])\n",
    "axes[0].set_ylim(0.967, 0.99)\n",
    "plt.title('Average Recall (%)')\n",
    "\n",
    "sns.barplot(y='precision', x=result_df_clf_all.index, data=result_df_clf_all, ax = axes[1])\n",
    "axes[1].set_ylim(0.967, 0.99)\n",
    "plt.title('Average precision (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the baseline to 0.967 we can exclude all model in which reached accuracies below. Therefore, only the Random Forest (RF) and MLP performed properly. Having the R outperforming in about 1% in average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 02 - Test another models:\n",
    "- Bagged classifiers with AdaBoost algorithm;\n",
    "- No feature selection employed;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definitions\n",
    "results_obj_name = 'results-02-clf-adaboost.pkl'\n",
    "results_folder = os.path.join('Results-analyses-3', '02-Adaboost')\n",
    "kfolds = 10\n",
    "n_classes = 2\n",
    "\n",
    "# CLF definitions\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)\n",
    "\n",
    "bnn = AdaBoostClassifier(SGDClassifier(),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=50)\n",
    "\n",
    "classifiers_adabost = {'BDT': bdt, 'BNN': bnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_exp_02 = do_experiment(results_obj_name, results_folder, features=features.values, labels=labels.values.ravel(), \n",
    "                               classifiers=classifiers_adabost, n_classes=n_classes, action='load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_bagged = see_results(results_exp_02)\n",
    "result_df_bagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(15,6))\n",
    "sns.barplot(y='acc', x=result_df_bagged.index, data=result_df_bagged)\n",
    "plt.ylim(0.967, 0.99)\n",
    "plt.title('Average ACC (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1,figsize=(15,10))\n",
    "sns.barplot(y='recall', x=result_df_bagged.index, data=result_df_bagged, ax = axes[0])\n",
    "axes[0].set_ylim(0.967, 0.99)\n",
    "plt.title('Average Recall (%)')\n",
    "\n",
    "sns.barplot(y='precision', x=result_df_bagged.index, data=result_df_bagged, ax = axes[1])\n",
    "axes[1].set_ylim(0.967, 0.99)\n",
    "plt.title('Average precision (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bagged of decisions tree performed almost as the RF, so there wont be necessary to use them from now. The bagged of Perceptrons will not be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 03:\n",
    "- The \"best\" classifiers up until now (RF and  MLP)\n",
    "- Feature selection in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected = pipeline_02.fit_transform(info_data)\n",
    "features_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 14 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "results_obj_name = 'results-03-clf-feat_selected.pkl'\n",
    "results_folder = os.path.join('Results-analyses-3', '03-Feature-selected')\n",
    "kfolds = 10\n",
    "n_classes = 2\n",
    "\n",
    "# CLF definitions as  the same above in the Expr 01\n",
    "classifiers_feat_selected = {'MLP': mlp_clf, 'RF': random_forest_clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_exp_03 = do_experiment(results_obj_name, results_folder, features=features_selected.values, labels=labels.values.ravel(), \n",
    "                               classifiers=classifiers_feat_selected, n_classes=n_classes, action='load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_feat_selected = see_results(results_exp_03)\n",
    "result_df_feat_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_comparison = pd.DataFrame([result_df_clf_all.loc['RF']['acc'], result_df_feat_selected.loc['RF']['acc']],\n",
    "                                    index=['47 features', '14 features'], columns=['RF'])\n",
    "\n",
    "results_comparison['MLP'] = [result_df_clf_all.loc['MLP']['acc'], result_df_feat_selected.loc['MLP']['acc']]\n",
    "results_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=results_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=20):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = print_confusion_matrix(results_exp_03['test']['MLP']['confMat'][9], class_names=np.array(['Assinante', 'Cancelou']))\n",
    "plt.title('MLP confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = print_confusion_matrix(results_exp_03['test']['RF']['confMat'][9], class_names=np.array(['Assinante', 'Cancelou']))\n",
    "plt.title('RF confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There have  been a  slightly improvement about 0.2% by using only 14 features. So, it would not harm to use only 14 features. In this way, the RF and MLP seem to be most suitable. We now want to test them on a larger part of the database and see how they perform. Let's train them all this whole database and test on the larger one called:\n",
    "- `user-status-after_chunk_30.csv` \n",
    "- `weekly-infos-before_chunk_30.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the another part of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_DATA = 'user-status-after_chunk_30.csv'\n",
    "INFO_DATA = 'weekly-infos-before_chunk_30.csv'\n",
    "\n",
    "info_data_30 = pd.read_csv(os.path.join(DATA_FOLDER, INFO_DATA), index_col=0)\n",
    "user_data_30 = pd.read_csv(os.path.join(DATA_FOLDER, USER_DATA), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_30.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is about 1M entries and 140k users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform with the pipeline 02\n",
    "**WARNING**: ONLY TRANSFORM. DO NOT CALL *FIT_TRANSFORM* METHOD, SINCE IT WOULD ADD BIAS ON THE FEATURE SCALING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_30 = pipeline_02.transform(info_data_30)\n",
    "features_30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_30 = GetLables().transform(user_data_30, features_30)\n",
    "labels_30['status'] = labels_30['status'].map({'assinante':0, 'cancelou': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is about 120k users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the clf on the 6% of the data and test on the 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf.fit(X=features_selected.values, y=labels.values.ravel())\n",
    "random_forest_clf.fit(X=features_selected.values, y=labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = mlp_clf.predict(features_30.values)\n",
    "y_pred_rf = random_forest_clf.predict(features_30.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "target_names = ['Assinante', 'Cancelou']\n",
    "print('RF:')\n",
    "print(classification_report(labels_30.values.ravel(), y_pred_rf, target_names=target_names))\n",
    "\n",
    "print('MLP:')\n",
    "print(classification_report(labels_30.values.ravel(), y_pred_mlp, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RF confusion matrix:')\n",
    "print(confusion_matrix(labels_30.values.ravel(), y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MLP confusion matrix:')\n",
    "print(confusion_matrix(labels_30.values.ravel(), y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems weird!\n",
    "Despite performing similar behavior in the cross validation made with only 6% of the data, when subjected to 30% of the data the Random Forest starts to decay its performance. Specialy in the class \"**Assinante**\". RF is extremelly susceptive to overfitting and that might be reason. From now on we will be employing the MLP as our main classifier for this problem.\n",
    "\n",
    "While working with neural networks there is always the question: *How to proper define the best hyperparameters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP:\n",
    "mlp_clf = MLPClassifier(solver='adam', learning_rate='adaptive', max_iter=1300, learning_rate_init=5e-04, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_dict = {'MLP': {\"hidden_layer_sizes\": list(np.arange(2,1001))}\n",
    "                  }\n",
    "\n",
    "classifiers = {'MLP': mlp_clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = dict((k,[]) for k in classifiers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_obj_name = 'results-04-mlp-random-search.pkl'\n",
    "results_folder = os.path.join('Results-analyses-3', '02-Adaboost')\n",
    "\n",
    "if ACTION == 'train':\n",
    "    for clf in param_dist_dict.keys():\n",
    "        random_search[clf] = RandomizedSearchCV(classifiers[clf], param_dist_dict[clf], cv=10, n_iter=50, verbose=5, scoring='precision')\n",
    "        random_search[clf].fit(features_selected.values, y=labels.values.ravel())\n",
    "        joblib.dump(random_search, os.path.join(results_folder, results_obj_name))\n",
    "else:\n",
    "    random_search = joblib.load('random-search.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best_mlp = random_search['MLP'].best_estimator_.predict(features_30.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels_30.values.ravel(), y_pred_best_mlp, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search['MLP'].best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems it has improved a bit, with 487 neurons, however we are not convinced. We will keep using the default config of 100 neurons for proper evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(labels_30.values.ravel(), y_pred_best_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(labels_30.values.ravel(), y_pred_best_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_30.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In respect to the data preprocessing etc.\n",
    "\n",
    "A whole pipeline is built with the `transforms.py`. Data cleaning, Categorical preprocessing and numerical preprocessing are employed. Two are tested agains the classifiers: (i) one with **Feature Selection** and (ii) one without it.\n",
    "\n",
    "- In respect to the classifiers:\n",
    "\n",
    "Different classifiers are are evaluated in the first chunkg of data, the one which contains 6%. The two most promossing, the Random Forest and the Multi-layer Perpectron are choosen to be trained with the whole chunk of 6% and teste agains the one with 30%. The RF performed worse on the \"Assinante\" class, indicating overfitting. We procced the experiments with the MLP, which will be the one choosen to desing the alpha version of the model.\n",
    "\n",
    "- The proposed pipeline and model:\n",
    "\n",
    "The feature map is processed and reduced to 14 features in which the MLP with 100 and 487 neurons are to be used in the next step of analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
